{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avulsion fracture', 'Comminuted fracture', 'Fracture Dislocation', 'Greenstick fracture', 'Hairline Fracture', 'Impacted fracture', 'Longitudinal fracture', 'Oblique fracture', 'Pathological fracture', 'Spiral Fracture']\n"
     ]
    }
   ],
   "source": [
    "path = 'Bone Break Classification'\n",
    "class_list = os.listdir(path)\n",
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum width: 640\n",
      "Maximum height: 640\n",
      "Max size: 640x640\n"
     ]
    }
   ],
   "source": [
    "max_width = 0\n",
    "max_height = 0\n",
    "\n",
    "for (index, _class) in enumerate(class_list):\n",
    "    class_path = os.path.join(path, _class)\n",
    "\n",
    "    train_path = os.path.join(class_path, 'Train')\n",
    "    for img_path in os.listdir(train_path):\n",
    "        full_path = os.path.join(train_path, img_path)\n",
    "        image = cv2.imread(full_path,0)\n",
    "        height, width = image.shape[:2]\n",
    "        max_width = max(max_width, width)\n",
    "        max_height = max(max_height, height)\n",
    "\n",
    "    test_path = os.path.join(class_path, 'Test')\n",
    "    for img_path in os.listdir(test_path):\n",
    "        full_path = os.path.join(test_path, img_path)\n",
    "        image = cv2.imread(full_path,0)\n",
    "        height, width = image.shape[:2]\n",
    "        max_width = max(max_width, width)\n",
    "        max_height = max(max_height, height)\n",
    "\n",
    "print(f\"Maximum width: {max_width}\")\n",
    "print(f\"Maximum height: {max_height}\")\n",
    "\n",
    "max_size = max(max_height, max_width)\n",
    "print(f\"Max size: {max_size}x{max_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_padding(image, target_size):\n",
    "    old_size = image.shape[:2]  \n",
    "    ratio = float(target_size) / max(old_size)  \n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  \n",
    "\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "    delta_w = target_size - new_size[1]\n",
    "    delta_h = target_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    \n",
    "    color = [0, 0, 0]  \n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_classes = [], []\n",
    "test_images, test_classes = [], []\n",
    "\n",
    "for (index, _class) in enumerate(class_list):\n",
    "    class_path = os.path.join(path, _class)\n",
    "\n",
    "    train_path = os.path.join(class_path, 'Train')\n",
    "    for img_path in os.listdir(train_path):\n",
    "        full_path = os.path.join(train_path, img_path)\n",
    "        image = cv2.imread(full_path,0)\n",
    "        resized_image = resize_with_padding(image, max_size)\n",
    "        train_images.append(resized_image)\n",
    "        train_classes.append(index)\n",
    "\n",
    "    test_path = os.path.join(class_path, 'Test')\n",
    "    for img_path in os.listdir(test_path):\n",
    "        full_path = os.path.join(test_path, img_path)\n",
    "        image = cv2.imread(full_path,0)\n",
    "        resized_image = resize_with_padding(image, max_size)\n",
    "        test_images.append(resized_image)\n",
    "        test_classes.append(index)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "train_images = np.array(train_images)\n",
    "test_classes = np.array(test_classes)\n",
    "train_classes = np.array(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image_list):\n",
    "    return np.array([img.astype(np.float32) / 255.0 for img in image_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 640, 640)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_test_images = normalize(test_images)\n",
    "normalized_train_images = normalize(train_images)\n",
    "normalized_test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_class = len(set(train_classes))\n",
    "train_classes_categorical = tf.keras.utils.to_categorical(train_classes, total_class)\n",
    "test_classes_categorical = tf.keras.utils.to_categorical(test_classes, total_class)\n",
    "# print(test_classes_categorical)\n",
    "# test_classes_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalized_train_images.reshape(len(normalized_train_images), -1)\n",
    "X_test = normalized_test_images.reshape(len(normalized_test_images), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(train_classes_categorical, axis=-1)\n",
    "y_test = np.argmax(test_classes_categorical, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3,3),\n",
    "        activation='relu',\n",
    "        input_shape=(max_size, max_size, 1)\n",
    "    ),\n",
    "    tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2,2)\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3,3),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2,2)\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=128, \n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.5\n",
    "    ),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=64, \n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25\n",
    "    ),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=total_class, \n",
    "        activation='softmax'\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# CNN_history = CNN_model.fit(train_images, train_classes_categorical, epochs=10, batch_size = 32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; Received `input_shape=(640, 640, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19248\\3753501036.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[0mresnet50_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mpooling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mrequire_flatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     )\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"imagenet\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                     raise ValueError(\n\u001b[1;32m--> 402\u001b[1;33m                         \u001b[1;34m\"The input must have 3 channels; Received \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m                         \u001b[1;34mf\"`input_shape={input_shape}`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                     )\n",
      "\u001b[1;31mValueError\u001b[0m: The input must have 3 channels; Received `input_shape=(640, 640, 1)`"
     ]
    }
   ],
   "source": [
    "resnet50_base = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(max_size, max_size, 1)\n",
    ")\n",
    "resnet50_base.trainable = False\n",
    "\n",
    "resnet50_model = tf.keras.Sequential([\n",
    "    resnet50_base,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=128, \n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.5\n",
    "    ),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=64, \n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25\n",
    "    ),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=total_class, \n",
    "        activation='softmax'\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# resnet50_history = CNN_model.fit(train_images, train_classes_categorical, epochs=10, batch_size = 32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(\n",
    "    kernel='linear',\n",
    "    probability=True\n",
    ")\n",
    "svc_model.fit(X_train, y_train)\n",
    "svc_prediction = svc_model.predict(X_test)\n",
    "svc_report = classification_report(y_test, svc_prediction)\n",
    "svc_accuracy = accuracy_score(y_test, svc_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svc_model.pkl', 'wb') as file:\n",
    "    pickle.dump(svc_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_prediction = svc_model.predict(X_test)\n",
    "rf_report = classification_report(y_test, rf_prediction)\n",
    "rf_accuracy = accuracy_score(y_test, rf_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
